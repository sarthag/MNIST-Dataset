{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MNIST_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthag/MNIST-Dataset/blob/main/MNIST_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxr8Tb3xgM7y"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFpXBdWz7wPr"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUw0j_m5XHt"
      },
      "source": [
        "#parameters\n",
        "in_channel = 1\n",
        "input_size = 28\n",
        "sequence_length = 28\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4IARDj-nlk"
      },
      "source": [
        "def basic_test(model):\n",
        "  model = model\n",
        "  x = torch.randn(64,28,28).to(device)\n",
        "  start = time.process_time()\n",
        "  print(model(x).shape)\n",
        "  end = time.process_time()\n",
        "  print(\"time: \", end - start)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KbNZNReAKzg"
      },
      "source": [
        "def chk_accuracy(loader, model):\n",
        "    \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device = device)\n",
        "      y = y.to(device = device)\n",
        "      scores = model(x)\n",
        "      predictions = scores.argmax(1)\n",
        "      num_correct += sum((predictions == y))\n",
        "      num_samples += predictions.size(0)\n",
        "            \n",
        "    return float(num_correct)/float(num_samples)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-9WNT_s-aKY"
      },
      "source": [
        "def train(model):\n",
        "  loss_fun = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "      model = model.to(device = device)\n",
        "\n",
        "      loss_train = 0\n",
        "      start = time.process_time()\n",
        "      for batch, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device = device)\n",
        "        targets = targets.to(device= device)\n",
        "          \n",
        "        #Forward Prop\n",
        "        scores = model(data)\n",
        "        loss = loss_fun(scores, targets)\n",
        "          \n",
        "        #Back prop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        loss_train += loss.item()\n",
        "\n",
        "        #Optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "      train_acc = chk_accuracy(train_loader, model)\n",
        "      val_acc = chk_accuracy(test_loader, model)\n",
        "      avg_loss = loss_train/(len(train_loader))\n",
        "      end = time.process_time()\n",
        "\n",
        "      print('Epoch ({}/{}),Training loss : {:.4f}, Time: {:.2f}, train_accuracy:{:.4f}, val_accuracy:{:.4f}'.format(epoch+1, num_epochs, avg_loss, end - start, train_acc, val_acc))\n",
        "\n",
        "  return model\n",
        "                                "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce6m8f6N5fxM"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    out, _ = self.rnn(x, h0)\n",
        "    out = out.reshape(out.shape[0], -1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib3hsWB9-zzh",
        "outputId": "29cd7b87-22a5-4237-f15b-5947834d9e4d"
      },
      "source": [
        "model_RNN = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_RNN)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.03894231200000009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TknwztY-FLD"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(GRU,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    out, _ = self.gru(x, h0)\n",
        "    out = out.reshape(out.shape[0], -1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbT6XF0N-FZ-",
        "outputId": "193429e4-1f8b-4787-9f67-bfb7fd5c86c3"
      },
      "source": [
        "model_GRU = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_GRU)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.08117349099999993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkfdPy8KgM8Y"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(LSTM,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    out, _ = self.lstm(x, (h0,c0))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1yr4owS-XOT",
        "outputId": "1bf4947a-a88f-496d-e260-15732ecf9a5f"
      },
      "source": [
        "model_LSTM = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_LSTM)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.08186690899999993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE4YBzSHfQ8C"
      },
      "source": [
        "class BLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(BLSTM,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n",
        "    self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    out, _ = self.lstm(x, (h0,c0))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHr9cq7lfRG8",
        "outputId": "40cce24a-f9d5-4b58-c907-61e50fcf35c6"
      },
      "source": [
        "model_BLSTM = BLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_BLSTM)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.20212540700000003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I430lE7YgM8g",
        "outputId": "89d35aa4-3399-4d23-e5eb-7a71a0832b6a"
      },
      "source": [
        "#loading the data\n",
        "\n",
        "X,y = fetch_openml(\"mnist_784\", version = 1, return_X_y = True)\n",
        "\n",
        "X = X.astype(np.float32)\n",
        "y = np.int_(y)\n",
        "X = X.reshape(X.shape[0], 28, 28)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 28, 28) (70000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Fb0TDbgM8j"
      },
      "source": [
        "X_tensor = torch.from_numpy(X)\n",
        "y_tensor = torch.from_numpy(y)\n",
        "y_tensor = y_tensor.type(torch.LongTensor)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor,y_tensor, test_size = (1/7), random_state = 42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B-9dBzNhVlI"
      },
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yawwX7d6igfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1da284-1687-4437-bc62-45186ef7afc2"
      },
      "source": [
        "model_RNN = train(model_RNN)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.2677, Time: 73.58, train_accuracy:0.9614, val_accuracy:0.9548\n",
            "Epoch (2/2),Training loss : 0.2021, Time: 73.29, train_accuracy:0.9648, val_accuracy:0.9572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5YGoSvigM8n",
        "outputId": "cc71b5fa-d600-4578-f72c-cc86051b0029"
      },
      "source": [
        "model_GRU = train(model_GRU)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.1648, Time: 234.34, train_accuracy:0.9717, val_accuracy:0.9656\n",
            "Epoch (2/2),Training loss : 0.0958, Time: 251.50, train_accuracy:0.9800, val_accuracy:0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_rsdl4oAVfJ",
        "outputId": "4a6f3b4f-212c-45bf-984b-983a76789037"
      },
      "source": [
        "model_LSTM = train(model_LSTM)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.2447, Time: 610.82, train_accuracy:0.9742, val_accuracy:0.9682\n",
            "Epoch (2/2),Training loss : 0.0863, Time: 832.97, train_accuracy:0.9820, val_accuracy:0.9761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAqri0zWga6t",
        "outputId": "01f78e01-e39b-4201-b76f-2c2c7ef30124"
      },
      "source": [
        "model_BLSTM = train(model_BLSTM)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.2490, Time: 1561.01, train_accuracy:0.9722, val_accuracy:0.9667\n",
            "Epoch (2/2),Training loss : 0.0913, Time: 2123.31, train_accuracy:0.9812, val_accuracy:0.9760\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}