{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MNIST_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthag/MNIST-Dataset/blob/main/MNIST_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxr8Tb3xgM7y"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFpXBdWz7wPr"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUw0j_m5XHt"
      },
      "source": [
        "#parameters\n",
        "in_channel = 1\n",
        "input_size = 28\n",
        "sequence_length = 28\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4IARDj-nlk"
      },
      "source": [
        "def basic_test(model):\n",
        "  model = model\n",
        "  x = torch.randn(64,28,28).to(device)\n",
        "  start = time.process_time()\n",
        "  print(model(x).shape)\n",
        "  end = time.process_time()\n",
        "  print(\"time: \", end - start)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KbNZNReAKzg"
      },
      "source": [
        "def chk_accuracy(loader, model):\n",
        "    \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device = device)\n",
        "      y = y.to(device = device)\n",
        "      scores = model(x)\n",
        "      predictions = scores.argmax(1)\n",
        "      num_correct += sum((predictions == y))\n",
        "      num_samples += predictions.size(0)\n",
        "            \n",
        "    return float(num_correct)/float(num_samples)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-9WNT_s-aKY"
      },
      "source": [
        "def train(model):\n",
        "  loss_fun = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "      model = model.to(device = device)\n",
        "\n",
        "      loss_train = 0\n",
        "      start = time.process_time()\n",
        "      for batch, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device = device)\n",
        "        targets = targets.to(device= device)\n",
        "          \n",
        "        #Forward Prop\n",
        "        scores = model(data)\n",
        "        loss = loss_fun(scores, targets)\n",
        "          \n",
        "        #Back prop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        loss_train += loss.item()\n",
        "\n",
        "        #Optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "      train_acc = chk_accuracy(train_loader, model)\n",
        "      val_acc = chk_accuracy(test_loader, model)\n",
        "      avg_loss = loss_train/(len(train_loader))\n",
        "      end = time.process_time()\n",
        "\n",
        "      print('Epoch ({}/{}),Training loss : {:.4f}, Time: {:.2f}, train_accuracy:{:.4f}, val_accuracy:{:.4f}'.format(epoch+1, num_epochs, avg_loss, end - start, train_acc, val_acc))\n",
        "\n",
        "  return model\n",
        "                                "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce6m8f6N5fxM"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    out, _ = self.rnn(x, h0)\n",
        "    out = out.reshape(out.shape[0], -1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib3hsWB9-zzh",
        "outputId": "6ce769ce-6c57-4727-85f9-7baecb65f40a"
      },
      "source": [
        "model_RNN = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_RNN)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.027415200000000084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TknwztY-FLD"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(GRU,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    out, _ = self.gru(x, h0)\n",
        "    out = out.reshape(out.shape[0], -1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbT6XF0N-FZ-",
        "outputId": "c9754b0c-2781-4873-c73d-4bebf8042527"
      },
      "source": [
        "model_GRU = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_GRU)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.07502132900000014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkfdPy8KgM8Y"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(LSTM,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    out, _ = self.lstm(x, (h0,c0))\n",
        "    out = out.reshape(out.shape[0], -1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1yr4owS-XOT",
        "outputId": "9dfde0c6-a6b6-4f10-c49c-114fd0efdbf3"
      },
      "source": [
        "model_LSTM = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "basic_test(model_LSTM)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.08758508500000017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I430lE7YgM8g",
        "outputId": "3d79bbe8-e5e8-42f9-8fc4-089e1b135ff9"
      },
      "source": [
        "#loading the data\n",
        "\n",
        "X,y = fetch_openml(\"mnist_784\", version = 1, return_X_y = True)\n",
        "\n",
        "X = X.astype(np.float32)\n",
        "y = np.int_(y)\n",
        "X = X.reshape(X.shape[0], 28, 28)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 28, 28) (70000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Fb0TDbgM8j"
      },
      "source": [
        "X_tensor = torch.from_numpy(X)\n",
        "y_tensor = torch.from_numpy(y)\n",
        "y_tensor = y_tensor.type(torch.LongTensor)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor,y_tensor, test_size = (1/7), random_state = 42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B-9dBzNhVlI"
      },
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yawwX7d6igfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f069e3-5ac0-4c13-c47a-289d11545cfe"
      },
      "source": [
        "model_RNN = train(model_RNN)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.2699, Time: 72.81, train_accuracy:0.9520, val_accuracy:0.9470\n",
            "Epoch (2/2),Training loss : 0.1963, Time: 72.64, train_accuracy:0.9597, val_accuracy:0.9533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5YGoSvigM8n",
        "outputId": "ed60ce96-b465-476a-ecbd-15a99cdeb5bd"
      },
      "source": [
        "model_GRU = train(model_GRU)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.1583, Time: 231.94, train_accuracy:0.9725, val_accuracy:0.9693\n",
            "Epoch (2/2),Training loss : 0.0962, Time: 248.51, train_accuracy:0.9625, val_accuracy:0.9539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_rsdl4oAVfJ",
        "outputId": "84ec2003-12be-4444-be13-b83d7f5f9a32"
      },
      "source": [
        "model_LSTM = train(model_LSTM)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/2),Training loss : 0.1401, Time: 524.56, train_accuracy:0.9825, val_accuracy:0.9752\n",
            "Epoch (2/2),Training loss : 0.0622, Time: 742.13, train_accuracy:0.9849, val_accuracy:0.9781\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}