{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MNIST_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthag/MNIST-Dataset/blob/main/MNIST_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8bjTJ-yvDqD"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URW6mZyqvDqO"
      },
      "source": [
        "#define the NN model\n",
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 50)\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK1bd7jPvS2I"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VUfYsMdvDqP",
        "outputId": "63e14857-8898-4c3d-e5f0-d2bf6e8a6605"
      },
      "source": [
        "#Basic Test\n",
        "model = NN(784, 10)\n",
        "x = torch.randn(64,784)\n",
        "model = model.to(device)\n",
        "x = x.to(device)\n",
        "start = time.process_time()\n",
        "print(model(x).shape)\n",
        "end = time.process_time()\n",
        "print(\"time: \", end - start)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "time:  0.0009015619999996893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ1zzbGvvDqR"
      },
      "source": [
        "#parameters\n",
        "in_channel = 1\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3_X82ixvDqS",
        "outputId": "24dc0f34-63ac-4bc4-bf5f-84f4f81ce7e9"
      },
      "source": [
        "#loading the data\n",
        "\n",
        "X,y = fetch_openml(\"mnist_784\", version = 1, return_X_y = True)\n",
        "\n",
        "X = X.astype(np.float32)\n",
        "y = np.int_(y)\n",
        "X = X.reshape(X.shape[0], 784)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 784) (70000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7sXo9UvDqS"
      },
      "source": [
        "X_tensor = torch.from_numpy(X)\n",
        "y_tensor = torch.from_numpy(y)\n",
        "y_tensor = y_tensor.type(torch.LongTensor)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor,y_tensor, test_size = (1/7), random_state = 42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJP8t0yWvkPT"
      },
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcP3Qc0vDqT"
      },
      "source": [
        "#initialise network\n",
        "model = NN(784, num_classes)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55XBURFvoVx"
      },
      "source": [
        "def chk_accuracy(loader, model):\n",
        "    \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device = device)\n",
        "      y = y.to(device = device)\n",
        "      scores = model(x)\n",
        "      predictions = scores.argmax(1)\n",
        "      num_correct += sum((predictions == y))\n",
        "      num_samples += predictions.size(0)\n",
        "            \n",
        "    return float(num_correct)/float(num_samples)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd-JI4tOvDqV",
        "outputId": "d5ef6da1-874f-4388-b7fc-f0ddd9728f64"
      },
      "source": [
        "#Train the network\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "    model = model.to(device = device)\n",
        "\n",
        "    loss_train = 0\n",
        "    start = time.process_time()\n",
        "    for batch, (data, targets) in enumerate(train_loader):\n",
        "      data = data.to(device = device)\n",
        "      targets = targets.to(device= device)\n",
        "        \n",
        "      #Forward Prop\n",
        "      scores = model(data)\n",
        "      loss = loss_fun(scores, targets)\n",
        "        \n",
        "      #Back prop\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      loss_train += loss.item()\n",
        "\n",
        "      #Optimizer\n",
        "      optimizer.step()\n",
        "\n",
        "    train_acc = chk_accuracy(train_loader, model)\n",
        "    val_acc = chk_accuracy(test_loader, model)\n",
        "    avg_loss = loss_train/(len(train_loader))\n",
        "    end = time.process_time()\n",
        "\n",
        "    print('Epoch ({}/{}),Training loss : {:.4f}, Time: {:.2f}, train_accuracy:{:.4f}, val_accuracy:{:.4f}'.format(epoch+1, num_epochs, avg_loss, end - start, train_acc, val_acc))\n",
        "                                "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/100),Training loss : 0.6907, Time: 2.79, train_accuracy:0.9320, val_accuracy:0.9261\n",
            "Epoch (2/100),Training loss : 0.2283, Time: 3.02, train_accuracy:0.9492, val_accuracy:0.9379\n",
            "Epoch (3/100),Training loss : 0.1843, Time: 3.03, train_accuracy:0.9506, val_accuracy:0.9412\n",
            "Epoch (4/100),Training loss : 0.1694, Time: 3.00, train_accuracy:0.9510, val_accuracy:0.9391\n",
            "Epoch (5/100),Training loss : 0.1651, Time: 3.03, train_accuracy:0.9555, val_accuracy:0.9403\n",
            "Epoch (6/100),Training loss : 0.1533, Time: 3.07, train_accuracy:0.9628, val_accuracy:0.9485\n",
            "Epoch (7/100),Training loss : 0.1483, Time: 3.04, train_accuracy:0.9581, val_accuracy:0.9420\n",
            "Epoch (8/100),Training loss : 0.1449, Time: 3.06, train_accuracy:0.9629, val_accuracy:0.9465\n",
            "Epoch (9/100),Training loss : 0.1437, Time: 3.10, train_accuracy:0.9655, val_accuracy:0.9462\n",
            "Epoch (10/100),Training loss : 0.1380, Time: 3.04, train_accuracy:0.9615, val_accuracy:0.9455\n",
            "Epoch (11/100),Training loss : 0.1350, Time: 3.07, train_accuracy:0.9643, val_accuracy:0.9459\n",
            "Epoch (12/100),Training loss : 0.1319, Time: 3.04, train_accuracy:0.9660, val_accuracy:0.9470\n",
            "Epoch (13/100),Training loss : 0.1265, Time: 3.06, train_accuracy:0.9707, val_accuracy:0.9498\n",
            "Epoch (14/100),Training loss : 0.1237, Time: 3.05, train_accuracy:0.9679, val_accuracy:0.9474\n",
            "Epoch (15/100),Training loss : 0.1212, Time: 3.06, train_accuracy:0.9709, val_accuracy:0.9524\n",
            "Epoch (16/100),Training loss : 0.1178, Time: 3.07, train_accuracy:0.9740, val_accuracy:0.9531\n",
            "Epoch (17/100),Training loss : 0.1176, Time: 3.07, train_accuracy:0.9698, val_accuracy:0.9496\n",
            "Epoch (18/100),Training loss : 0.1139, Time: 3.05, train_accuracy:0.9714, val_accuracy:0.9488\n",
            "Epoch (19/100),Training loss : 0.1137, Time: 3.10, train_accuracy:0.9729, val_accuracy:0.9503\n",
            "Epoch (20/100),Training loss : 0.1139, Time: 3.07, train_accuracy:0.9709, val_accuracy:0.9515\n",
            "Epoch (21/100),Training loss : 0.1058, Time: 3.09, train_accuracy:0.9743, val_accuracy:0.9525\n",
            "Epoch (22/100),Training loss : 0.1087, Time: 3.10, train_accuracy:0.9682, val_accuracy:0.9466\n",
            "Epoch (23/100),Training loss : 0.1111, Time: 3.10, train_accuracy:0.9688, val_accuracy:0.9454\n",
            "Epoch (24/100),Training loss : 0.1083, Time: 3.11, train_accuracy:0.9716, val_accuracy:0.9497\n",
            "Epoch (25/100),Training loss : 0.1079, Time: 3.11, train_accuracy:0.9697, val_accuracy:0.9480\n",
            "Epoch (26/100),Training loss : 0.1008, Time: 3.10, train_accuracy:0.9710, val_accuracy:0.9478\n",
            "Epoch (27/100),Training loss : 0.1108, Time: 3.12, train_accuracy:0.9726, val_accuracy:0.9495\n",
            "Epoch (28/100),Training loss : 0.1027, Time: 3.09, train_accuracy:0.9689, val_accuracy:0.9432\n",
            "Epoch (29/100),Training loss : 0.1025, Time: 3.12, train_accuracy:0.9718, val_accuracy:0.9468\n",
            "Epoch (30/100),Training loss : 0.1046, Time: 3.12, train_accuracy:0.9751, val_accuracy:0.9504\n",
            "Epoch (31/100),Training loss : 0.1016, Time: 3.10, train_accuracy:0.9772, val_accuracy:0.9529\n",
            "Epoch (32/100),Training loss : 0.0935, Time: 3.11, train_accuracy:0.9746, val_accuracy:0.9494\n",
            "Epoch (33/100),Training loss : 0.0973, Time: 3.18, train_accuracy:0.9788, val_accuracy:0.9524\n",
            "Epoch (34/100),Training loss : 0.0989, Time: 3.10, train_accuracy:0.9786, val_accuracy:0.9542\n",
            "Epoch (35/100),Training loss : 0.1004, Time: 3.16, train_accuracy:0.9753, val_accuracy:0.9520\n",
            "Epoch (36/100),Training loss : 0.0967, Time: 3.16, train_accuracy:0.9768, val_accuracy:0.9517\n",
            "Epoch (37/100),Training loss : 0.0908, Time: 3.12, train_accuracy:0.9744, val_accuracy:0.9480\n",
            "Epoch (38/100),Training loss : 0.0960, Time: 3.18, train_accuracy:0.9763, val_accuracy:0.9502\n",
            "Epoch (39/100),Training loss : 0.0946, Time: 3.16, train_accuracy:0.9774, val_accuracy:0.9507\n",
            "Epoch (40/100),Training loss : 0.0920, Time: 3.17, train_accuracy:0.9764, val_accuracy:0.9512\n",
            "Epoch (41/100),Training loss : 0.0890, Time: 3.18, train_accuracy:0.9748, val_accuracy:0.9471\n",
            "Epoch (42/100),Training loss : 0.0900, Time: 3.18, train_accuracy:0.9721, val_accuracy:0.9453\n",
            "Epoch (43/100),Training loss : 0.0973, Time: 3.16, train_accuracy:0.9773, val_accuracy:0.9505\n",
            "Epoch (44/100),Training loss : 0.0888, Time: 3.22, train_accuracy:0.9776, val_accuracy:0.9494\n",
            "Epoch (45/100),Training loss : 0.0881, Time: 3.19, train_accuracy:0.9782, val_accuracy:0.9496\n",
            "Epoch (46/100),Training loss : 0.0878, Time: 3.19, train_accuracy:0.9785, val_accuracy:0.9482\n",
            "Epoch (47/100),Training loss : 0.0820, Time: 3.20, train_accuracy:0.9818, val_accuracy:0.9500\n",
            "Epoch (48/100),Training loss : 0.0884, Time: 3.32, train_accuracy:0.9788, val_accuracy:0.9505\n",
            "Epoch (49/100),Training loss : 0.0925, Time: 3.22, train_accuracy:0.9755, val_accuracy:0.9451\n",
            "Epoch (50/100),Training loss : 0.0865, Time: 3.21, train_accuracy:0.9791, val_accuracy:0.9500\n",
            "Epoch (51/100),Training loss : 0.0883, Time: 3.22, train_accuracy:0.9768, val_accuracy:0.9477\n",
            "Epoch (52/100),Training loss : 0.0948, Time: 3.21, train_accuracy:0.9811, val_accuracy:0.9515\n",
            "Epoch (53/100),Training loss : 0.0838, Time: 3.20, train_accuracy:0.9789, val_accuracy:0.9504\n",
            "Epoch (54/100),Training loss : 0.0831, Time: 3.23, train_accuracy:0.9784, val_accuracy:0.9483\n",
            "Epoch (55/100),Training loss : 0.0948, Time: 3.26, train_accuracy:0.9788, val_accuracy:0.9478\n",
            "Epoch (56/100),Training loss : 0.0804, Time: 3.24, train_accuracy:0.9804, val_accuracy:0.9491\n",
            "Epoch (57/100),Training loss : 0.0891, Time: 3.30, train_accuracy:0.9790, val_accuracy:0.9490\n",
            "Epoch (58/100),Training loss : 0.0872, Time: 3.27, train_accuracy:0.9779, val_accuracy:0.9501\n",
            "Epoch (59/100),Training loss : 0.0874, Time: 3.28, train_accuracy:0.9802, val_accuracy:0.9508\n",
            "Epoch (60/100),Training loss : 0.0857, Time: 3.29, train_accuracy:0.9788, val_accuracy:0.9502\n",
            "Epoch (61/100),Training loss : 0.0837, Time: 3.27, train_accuracy:0.9762, val_accuracy:0.9450\n",
            "Epoch (62/100),Training loss : 0.0838, Time: 3.36, train_accuracy:0.9807, val_accuracy:0.9489\n",
            "Epoch (63/100),Training loss : 0.0865, Time: 3.34, train_accuracy:0.9834, val_accuracy:0.9509\n",
            "Epoch (64/100),Training loss : 0.0778, Time: 3.58, train_accuracy:0.9828, val_accuracy:0.9510\n",
            "Epoch (65/100),Training loss : 0.0935, Time: 3.69, train_accuracy:0.9810, val_accuracy:0.9498\n",
            "Epoch (66/100),Training loss : 0.0792, Time: 3.75, train_accuracy:0.9803, val_accuracy:0.9484\n",
            "Epoch (67/100),Training loss : 0.0855, Time: 3.52, train_accuracy:0.9834, val_accuracy:0.9525\n",
            "Epoch (68/100),Training loss : 0.0860, Time: 3.75, train_accuracy:0.9829, val_accuracy:0.9526\n",
            "Epoch (69/100),Training loss : 0.0865, Time: 3.82, train_accuracy:0.9795, val_accuracy:0.9452\n",
            "Epoch (70/100),Training loss : 0.0762, Time: 3.93, train_accuracy:0.9821, val_accuracy:0.9510\n",
            "Epoch (71/100),Training loss : 0.0790, Time: 3.80, train_accuracy:0.9790, val_accuracy:0.9501\n",
            "Epoch (72/100),Training loss : 0.0903, Time: 3.76, train_accuracy:0.9795, val_accuracy:0.9475\n",
            "Epoch (73/100),Training loss : 0.0792, Time: 3.80, train_accuracy:0.9818, val_accuracy:0.9527\n",
            "Epoch (74/100),Training loss : 0.0875, Time: 3.81, train_accuracy:0.9834, val_accuracy:0.9506\n",
            "Epoch (75/100),Training loss : 0.0775, Time: 4.00, train_accuracy:0.9830, val_accuracy:0.9500\n",
            "Epoch (76/100),Training loss : 0.0833, Time: 4.07, train_accuracy:0.9815, val_accuracy:0.9507\n",
            "Epoch (77/100),Training loss : 0.0879, Time: 4.22, train_accuracy:0.9833, val_accuracy:0.9525\n",
            "Epoch (78/100),Training loss : 0.0777, Time: 4.02, train_accuracy:0.9837, val_accuracy:0.9493\n",
            "Epoch (79/100),Training loss : 0.0809, Time: 3.99, train_accuracy:0.9825, val_accuracy:0.9503\n",
            "Epoch (80/100),Training loss : 0.0770, Time: 4.02, train_accuracy:0.9838, val_accuracy:0.9510\n",
            "Epoch (81/100),Training loss : 0.0787, Time: 3.79, train_accuracy:0.9822, val_accuracy:0.9517\n",
            "Epoch (82/100),Training loss : 0.0822, Time: 4.02, train_accuracy:0.9785, val_accuracy:0.9461\n",
            "Epoch (83/100),Training loss : 0.0803, Time: 3.96, train_accuracy:0.9804, val_accuracy:0.9474\n",
            "Epoch (84/100),Training loss : 0.0871, Time: 3.94, train_accuracy:0.9804, val_accuracy:0.9492\n",
            "Epoch (85/100),Training loss : 0.0759, Time: 3.81, train_accuracy:0.9836, val_accuracy:0.9507\n",
            "Epoch (86/100),Training loss : 0.0793, Time: 4.06, train_accuracy:0.9795, val_accuracy:0.9505\n",
            "Epoch (87/100),Training loss : 0.0841, Time: 4.15, train_accuracy:0.9779, val_accuracy:0.9464\n",
            "Epoch (88/100),Training loss : 0.0690, Time: 4.19, train_accuracy:0.9825, val_accuracy:0.9500\n",
            "Epoch (89/100),Training loss : 0.0814, Time: 4.22, train_accuracy:0.9818, val_accuracy:0.9499\n",
            "Epoch (90/100),Training loss : 0.0907, Time: 4.15, train_accuracy:0.9843, val_accuracy:0.9482\n",
            "Epoch (91/100),Training loss : 0.0712, Time: 4.30, train_accuracy:0.9837, val_accuracy:0.9495\n",
            "Epoch (92/100),Training loss : 0.0737, Time: 4.33, train_accuracy:0.9827, val_accuracy:0.9478\n",
            "Epoch (93/100),Training loss : 0.0808, Time: 4.39, train_accuracy:0.9815, val_accuracy:0.9503\n",
            "Epoch (94/100),Training loss : 0.0800, Time: 4.30, train_accuracy:0.9797, val_accuracy:0.9479\n",
            "Epoch (95/100),Training loss : 0.0824, Time: 4.34, train_accuracy:0.9815, val_accuracy:0.9479\n",
            "Epoch (96/100),Training loss : 0.0851, Time: 4.23, train_accuracy:0.9804, val_accuracy:0.9472\n",
            "Epoch (97/100),Training loss : 0.0688, Time: 4.21, train_accuracy:0.9834, val_accuracy:0.9485\n",
            "Epoch (98/100),Training loss : 0.0824, Time: 4.38, train_accuracy:0.9805, val_accuracy:0.9484\n",
            "Epoch (99/100),Training loss : 0.0821, Time: 4.45, train_accuracy:0.9843, val_accuracy:0.9498\n",
            "Epoch (100/100),Training loss : 0.0753, Time: 4.37, train_accuracy:0.9852, val_accuracy:0.9521\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}