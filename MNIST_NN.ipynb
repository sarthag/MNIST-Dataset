{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the Dataset \n",
    "X,y = fetch_openml(\"mnist_784\", version = 1, return_X_y = True)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.int_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining one hot encoding on y to simplify error checking \n",
    "def one_hot_encoding(y):\n",
    "    one_hot_y = np.zeros((np.amax(y) +1, y.size))\n",
    "    one_hot_y[y, np.arange(y.size)] = 1\n",
    "    return one_hot_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing one hot encoding\n",
    "y = one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the activiation sigmoid function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the functions necessary fer training the network\n",
    "\n",
    "#initializong weights and biases\n",
    "def init_par():\n",
    "    w1 = np.random.randn(25, 784)\n",
    "    b1 = np.random.randn(25, 1)\n",
    "    w2 = np.random.randn(10, 25)\n",
    "    b2 = np.random.randn(10, 1)\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "#defining the forward prop a0 -> a1 -> a2\n",
    "def fw_prop(w1, b1, w2, b2, X):\n",
    "    a0 = X.T\n",
    "    z1 = w1.dot(a0) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "\n",
    "#defining backward prop to obtain parameters for updation\n",
    "def bk_prop(z1, a1, z2, a2, w2, X, y):\n",
    "    m = X.shape[0]\n",
    "    p = 1/m\n",
    "    \n",
    "    da2 = (a2 - y.T)*deriv_sigmoid(z2)\n",
    "    dw2 = p*da2.dot(a1.T)\n",
    "    db2 = np.array([p*np.sum(da2)]).T\n",
    "    \n",
    "    da1 = w2.T.dot(da2)*deriv_sigmoid(z1) \n",
    "    dw1 = p*da1.dot(X)\n",
    "    db1 = np.array([p*np.sum(da1)]).T\n",
    "    \n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "\n",
    "#function to update parameters\n",
    "def upd_par(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    w1 -= lr * dw1\n",
    "    b1 -= lr * db1\n",
    "    w2 -= lr * dw2\n",
    "    b2 -= lr * db2\n",
    "    \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geadient descent function to train the neural net\n",
    "def gradient_descent(x, Y, epochs, alpha):\n",
    "    W1, b1 , W2, b2 = init_par()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        Z1, A1, Z2, A2 = fw_prop(W1, b1 , W2, b2, x)\n",
    "        dW1, db1, dW2, db2 = bk_prop(Z1, A1, Z2, A2, W2, x, Y)\n",
    "        W1, b1 , W2, b2 = upd_par(W1, b1 , W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "    return W1, b1, W2, b2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test the accuracy fot the NN for the test set\n",
    "def testNN(X, W1, b1 , W2, b2):\n",
    "    a0 = X.T\n",
    "    a1 = sigmoid(W1.dot(a0) + b1)\n",
    "    a2 = sigmoid(W2.dot(a1) + b2)\n",
    "    \n",
    "    return a2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine the score of the neural net\n",
    "def scoring(a2 ,y):\n",
    "    print(y)\n",
    "    print(a2)\n",
    "    error = np.mean(np.abs(y - a2))\n",
    "    score = 1 - error\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 10)\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "#Dividing dataset into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = (1/7), random_state = 42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "alpha = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a5148957ff78>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "#training the network to get necessary parameters\n",
    "W1, b1, W2, b2, A2 = gradient_descent(X_train, y_train, epochs, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[[1.01208309e-04 1.05408424e-01 2.52551610e-01 ... 4.93542947e-02\n",
      "  1.22723186e-04 6.20149248e-02]\n",
      " [5.52023932e-03 4.09838923e-02 2.53198528e-02 ... 1.84364945e-01\n",
      "  7.08530305e-05 9.64350899e-02]\n",
      " [5.42781235e-03 2.08597502e-01 5.02082415e-04 ... 1.34980499e-03\n",
      "  5.14450869e-02 2.70113956e-02]\n",
      " ...\n",
      " [2.97571632e-02 1.48094182e-01 5.33737095e-04 ... 2.21412098e-02\n",
      "  5.70365404e-04 3.92480991e-03]\n",
      " [1.98995321e-04 6.83783087e-03 7.38866832e-02 ... 1.31095861e-02\n",
      "  4.34528204e-04 2.67014635e-02]\n",
      " [5.26937065e-04 3.43367494e-01 3.12904618e-03 ... 1.57305462e-03\n",
      "  4.54893962e-03 8.78443858e-02]]\n",
      "training score: 0.8783338390506237\n"
     ]
    }
   ],
   "source": [
    "#determining the train score\n",
    "score = scoring(A2.T, y_train)\n",
    "print('training score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.00140263 0.02351121 0.00077194 ... 0.00914311 0.00061805 0.10159876]\n",
      " [0.00790896 0.04308933 0.00048213 ... 0.02262927 0.00014331 0.03649703]\n",
      " [0.03326418 0.02432448 0.0047906  ... 0.00558903 0.00172284 0.0189213 ]\n",
      " ...\n",
      " [0.00061282 0.00926022 0.00033816 ... 0.00774748 0.0008373  0.04528028]\n",
      " [0.00425201 0.01119353 0.00211313 ... 0.00325804 0.00256842 0.03922223]\n",
      " [0.00187138 0.0230825  0.00034139 ... 0.00704677 0.00349285 0.09409049]]\n",
      "test score: 0.877754164845185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a5148957ff78>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "#determining the test score\n",
    "a2_test = testNN(X_test, W1, b1, W2, b2)\n",
    "score = scoring(a2_test.T, y_test)\n",
    "print('test score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
