# -*- coding: utf-8 -*-
"""MNIST_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PDJw-gMVobVtYEnVkZHrpMS-GrF-GUTu
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
import torchvision.transforms as transforms
from torch.utils.data.dataset import TensorDataset
import time

class CNN(nn.Module):
    def __init__(self, in_channel =1, num_classes = 10):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3,3), stride = (1,1), padding = (1,1))
        self.pool = nn.MaxPool2d(kernel_size= (2,2), stride = (2,2))
        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3,3), stride = (1,1), padding = (1,1))
        self.fc1 = nn.Linear(16*7*7, num_classes)
    
    def forward(self, x):
        x = F.relu((self.conv1(x)))
        x = self.pool(x)
        x = self.conv2(x)
        x = self.pool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc1(x)
        return(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#Basic Test
model = CNN()
x = torch.randn(64,1,28,28)
model = model.to(device)
x = x.to(device)
start = time.process_time()
print(model(x).shape)
end = time.process_time()
print("time: ", end - start)

#parameters
in_channel = 1
num_classes = 10
learning_rate = 0.001
batch_size = 64
num_epochs = 25

#loading the data

X,y = fetch_openml("mnist_784", version = 1, return_X_y = True)

X = X.astype(np.float32)
y = np.int_(y)
X = X.reshape(X.shape[0], 1, 28, 28)
print(X.shape, y.shape)

X_tensor = torch.from_numpy(X)
y_tensor = torch.from_numpy(y)
y_tensor = y_tensor.type(torch.LongTensor)
X_train, X_test, y_train, y_test = train_test_split(X_tensor,y_tensor, test_size = (1/7), random_state = 42)

train_dataset = TensorDataset(X_train, y_train)
train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)
test_dataset = TensorDataset(X_test, y_test)
test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)

#initialise network
model = CNN()
loss_fun = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = learning_rate)

def chk_accuracy(loader, model):
    
  num_correct = 0
  num_samples = 0
  model.eval()
    
  with torch.no_grad():
    for x, y in loader:
      x = x.to(device = device)
      y = y.to(device = device)
      scores = model(x)
      predictions = scores.argmax(1)
      num_correct += sum((predictions == y))
      num_samples += predictions.size(0)
            
    return float(num_correct)/float(num_samples)

#Train the network
for epoch in range(num_epochs):
    model.train()
    if torch.cuda.is_available(): torch.cuda.empty_cache()
    model = model.to(device = device)

    loss_train = 0
    start = time.process_time()
    for batch, (data, targets) in enumerate(train_loader):
      data = data.to(device = device)
      targets = targets.to(device= device)
        
      #Forward Prop
      scores = model(data)
      loss = loss_fun(scores, targets)
        
      #Back prop
      optimizer.zero_grad()
      loss.backward()
      loss_train += loss.item()

      #Optimizer
      optimizer.step()

    train_acc = chk_accuracy(train_loader, model)
    val_acc = chk_accuracy(test_loader, model)
    avg_loss = loss_train/(len(train_loader))
    end = time.process_time()

    print('Epoch ({}/{}),Training loss : {:.4f}, Time: {:.2f}, train_accuracy:{:.4f}, val_accuracy:{:.4f}'.format(epoch+1, num_epochs, avg_loss, end - start, train_acc, val_acc))